WARNING: Under construction

TITLE: Splitting node and array allocation in C++ containers

AUTHOR: Marcelo Zimbres

Target audience

  - Realtime/embedded programming.
  - Games, high performace, 24/7 availability.
  - Should be usefull for c++ programmers in general.

Implementation available on github.

Allocators
======================================================================

  - Abstraction to memory allocation inside containers.
  - All containers with dynamic size request memory from
    their allocator internally.
  - The allocator is part of the container type.

    template<class T, class Allocator = std::allocator<T>>
    class list;

  Basic usage

  std::allocator<int> alloc;
  int* p = alloc.allocate(n);
  alloc.deallocate(p, n);

NOTE: Containers do not interact directly with the allocator but throgh
std::allocator_traits.

Allocation patterns in the standard library.
======================================================================

Allocation can divide containers in three groups.

(A) Perform only array allocation. (i.e. arbitrary n)

  std::vector

(B) Perform only node allocation. (i.e. compile time n)

  std::list
  std::forward_list
  std::set
  std::multiset
  std::map
  std::multimap

(C) Perfom both array and node allocation.

  std::deque
  std::unordered_set
  std::unordered_multiset
  std::unordered_map
  std::unordered_multimap
  
Summary: From 12 containers

  - 11 perform node allocation.
  - 6 perform exclusively node-allocation.
  - 5 perform both node and array allcation.

Node allocation is a pretty common pattern. Should it be standardized?
(See node allocator proposal.)

Node allocation
======================================================================

Node allocation

  - Simple and straighforward implementation.
  - Suitable for realtime/embedded.
  - Reduces memory fragmentation.
  - Basic building block used in array allocations as well.

  1 - Get a big block of memory.
  2 - Divide it in n small blocks.
  3 - Link the blocks. (Forward list).
        _____   _____   _____   _____   _____   _____    _____   
       |     | |     | |     | |     | |     | |     |  |     |     
       |     V |     V |     V |     V |     V |     V  |     V   
  |_______|_______|_______|_______|_______|_______|_______|   0

     /\    
     ||      
     ||   
    Head

Array allocation

  - Complex.
  - Has to handle different sizes.
  - Many possible strategies.
  - No silver bullet. Every problem requires a different approach.
  - Users do not want to care about this unless there is need.
  - malloc: suitable for large memory blocks, overused, hundreds of
    loc, system calls, etc.
  - May use node allocation as a building block.

Further benefits of node allocation: Reducing memory usage.
======================================================================

Node allocation

  - Allocate a block big enough to store n elements.
  - Link the elements in stack-like fashion.
  - If more elements are needed, allocate another block
    and repeat the precedure.
  - The underlying data structure of a node allocator is deque-like.

  If nodes are stored in a deque-like data structure, why do I address
  the elements with pointers?

  - A deque-like data structure supports indexed access to elements.
  - Pointers can be a big overhead for small element types.

Example: Nodes of a liked list.

  struct node {
    node* links[2]; // Support for 2^64 elements.
    int value;
  };

  - sizeof (node) = 24 bytes

  struct node {
    unsigned short links[2]; // Support for 2^16 elements.
    int value;
  };

  - sizeof (node) = 8 bytes.
  
Conclusion: Massive reduction of how much memory a container uses.
Benefits: More data in the cache.

How can we support this in C++
======================================================================

Let us have a look on how node is usually defined

template <class T, class Ptr>
struct node {
  using link_type = typename std::pointer_traits<Ptr>::template
    rebind<node<T, Ptr>>;
  link_type link[2];
  T key;
};

  - The pointer type is passed as a template argument (fancy poiter
    support).
  - A Pointer has to be allowed to rebind to a non-pointer type.


Avoiding (or preventing) array allocation.
======================================================================

It is actually not totally true that containers ask blocks with the
same size.

  - Not guaranteed by the standard.
  - We do not know what a container will do with the allocator
    and have to plan for everything (bad).
  - Allocator interface allow them if they want

   Allocator::allocate(n);
   Allocator::deallocate(p, n);

Possible solution: Check n every allocation

  pointer allocate(size_type n)
  {
    if (n == 1)
      return allocate_node();
    return allocate(n);
  }

  - If n != 1 always. No node allocation takes place.
  - Runtime condition if (n == 1) is most of the time useless.
  - If I (as user) want array allocation, I can built it up
    on the allocator where I have control and not on the containers
    where I do not.
  - Users should be able to prevent it from happening. Example

    std::array<char, 10 * n> arena = {{}};
    my::allocator<int> alloc(arena);
    std::forward_list<int> l(alloc);
    l = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10};

  I do not know how to implement this if array allocation takes place. 

Other solutions
======================================================================

Why not simply assert(n == 1) or throw?

  - Unportable code. May work with some libraries and not
  - Throw: Should be used if I ran out of memory not if allocator
    does not provide array allocation.

Proposed solution
======================================================================

 - Split the concept of node allocation from array allocation.
 - std::allocator_traits offers interface for both.

   allocate(n); // arbitray n
   deallocate(p, n); // arbitray n

   allocate_node(n);
   deallocate_node(p, n);

   // Ensures array allocation does not take place in that allocator.
   node_allocation_only = std::true_type.

Benefits
======================================================================

Performance, realtime, low-fragmentation.

